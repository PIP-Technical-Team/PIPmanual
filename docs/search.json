[{"path":"index.html","id":"welcome","chapter":"Welcome!","heading":"Welcome!","text":"internal guidelines technical process PIP project. Visit Github repository book.","code":""},{"path":"index.html","id":"team","chapter":"Welcome!","heading":"Team","text":"PIP technical team composed ….","code":""},{"path":"intro.html","id":"intro","chapter":"1 Introduction","heading":"1 Introduction","text":"","code":""},{"path":"intro.html","id":"ojectives","chapter":"1 Introduction","heading":"1.1 Ojectives","text":"book explains several things,overview project technical perspective.interaction R packages developed manage data calculations.different types data PIP project interaction .poverty calculator, table maker, Statistics Online (SOL) platform updated.Technical standalone procedure necessary execution parts project.","code":""},{"path":"intro.html","id":"technical-requirements","chapter":"1 Introduction","heading":"1.2 Technical requirements","text":"need make sure bookdown package installed computerRemember Rmd file contains one one chapter, chapter \ndefined first-level heading #.Make sure install latest version PIP R packages typing \nfollowing","code":"\ninstall.packages(\"bookdown\")\n\n# or the development version\ndevtools::install_github(\"rstudio/bookdown\")\nipkg <- utils::installed.packages()[, 1]\n\npip_install <- function(pkg, ipkg) {\n    if (isFALSE(pkg %in% ipkg)) {\n        gitcall <- paste0(\"PIP-Technical-Team/\", pkg)\n        remotes::install_github(gitcall, dependencies = TRUE)\n        TRUE\n    } else {\n        FALSE\n    }\n}\n\npkgs <- c(\"pipload\", \"pipaux\", \"wbpip\", \"piptb\", \"pipdm\", \"pipapi\")\n\n\npurrr::walk(pkgs, pip_install, ipkg = ipkg)"},{"path":"internal-workflow.html","id":"internal-workflow","chapter":"2 Internal Workflow","heading":"2 Internal Workflow","text":"chapter explains internal technical workflow PIP project. Many\ndifferent steps workflow explained detail \nchapters book. chapter, however, presents overview \nworkflow components.","code":""},{"path":"internal-workflow.html","id":"the-github-group","chapter":"2 Internal Workflow","heading":"2.1 The Github group","text":"technical code PIP project organized Git repositories \nGithub group /PIP-Technical-Team. \nneed granted collaborator status order contribute \nrepositories group. Also, many repositories play direct\nrole PIP technical workflow. intended documenting\nparts workflow testing purposes. example, repository \nbook–/PIPmanual–\npart workflow PIP, since necessary estimation. Yet,\nneed get familiar repositories case need make \ncontribution . chapter, however, focus \nunderstanding repositories affect directly PIP workflow.First, see overview workflow. overview \nbucket buckets workflow . Yet, important \noverview clear order understand pieces fall\ntogether. , unpack workflow buckets understand \ndetail.","code":""},{"path":"internal-workflow.html","id":"overview","chapter":"2 Internal Workflow","heading":"2.2 Overview","text":"workflow overview mainly composed four steps.Data acquisitionData preparationpre-computed indicatorsAPI feedingEach steps (buckets) prerequisite next one, something\nchanges one , necessary execute subsequent steps.","code":""},{"path":"internal-workflow.html","id":"data-acquisition","chapter":"2 Internal Workflow","heading":"2.3 Data acquisition","text":"understanding input data PIP acquired, need \nunderstand PIP data . PIP fed two kinds data: welfare data\nauxiliary data.Welfare data refers data files contain least one welfare\nvector one population expansion factor (.e., weights) vector. two\nvariables minimum data necessary estimate poverty inequality\nmeasures.1 files come four varieties; microdata,\ngroup data, bin data, synthetic data. details welfare can found \nSection 7. Regardless variety data, welfare\ndata PIP gathered Global Monitoring Database, GMD. \ncomprehensive explanation household data selected obtained,\nmay check chapter Acquiring household survey\ndataof \nmethodological PIP\nmanual.Microdata uploaded PRIMUS system regional teams \nPoverty Global Practice. , regional team follow GMD\nguidelines, verified Stata command {primus}. Rarely. \n{primus} command capture potential errors data. \ndetails Section 6As now (August 16, 2021), Group data divided two:\nhistorical group data new group data. Historical group data organized \nprovided PovcalNet team, sends Poverty GP included \ndatalibweb system. New group data collected poverty economist \ncorresponding country, shares regional focal team, \nshares PovcalNet team. new group data organized tested \nPovcalNet team send back poverty GP included \ndatalibweb system.Bin data refers welfare data countries poverty\neconomist. countries developed countries Canada \nJapan. main characteristic data available \nLISSY system LIS\ndata center, allow access \nentire microdata. Thus, need contract microdata 400 bins \nquantiles. code gathers LIS data available Github repository\nPovcalNet-Team/LIS_data.Finally, synthetic data, refers simulated microdata statistical\nprocedure. now (August 16, 2021), data \nestimated using multiple imputation techniques, calculation must\ntake account imputation-id variable. data calculated \npoverty economist country organizes global team \nPoverty GP.Auxiliary data refers data necessary temporally deflate line\nwelfare data, objective getting poverty estimates comparable \ntime, across countries, , importantly, able estimate regional\nglobal estimates. data national population, GDP, consumer\nprice index, purchasing parity power, etc. Auxiliary data also include metadata\ntime comparability type welfare aggregate. Since measure \nauxiliary data acquired differently, details explain Section\n8.","code":""},{"path":"internal-workflow.html","id":"data-preparation","chapter":"2 Internal Workflow","heading":"2.4 Data preparation","text":"step assumes welfare data properly organized datalibweb\nsystem vetted PRIMUS. contrast previous global-poverty\ncalculator system, PovcalNet, PIP system gathers welfare \ndatalibweb server.welfare data preparation done using repository\n/pipdp. now\n(August 16, 2021), part process coded\nStata, given R version {dataliweb}. \nauxiliary data preparation, done package {pipaux}, available \nrepository /pipaux. Right now\nautomation updating auxiliary implemented. Thus, \ndone manually typing pipaux::pip_update_all_aux() update \nmeasures, use function pipaux::update_aux() update particular measure.","code":""},{"path":"internal-workflow.html","id":"pre-computed-indicators","chapter":"2 Internal Workflow","heading":"2.5 Pre-computed indicators","text":"measures PIP depend value poverty line \npre-computed order make API efficient responsive. \nindicators depend poverty lines depend \nparameters, like societal poverty, included part \npre-computed indicators.step executed repository\n/pip_ingestion_pipeline,\npipeline powered targets package. process estimate\npre-computed indicators explained detail Chapter 9.\npipeline makes use two R packages, wbpip pipdm. former \npublicly available contains technical methodological procedures\nestimate poverty inequality measures country, regional, global\nlevel. latter, makes use wbpip execute calculations put\nresulting data order, ready ingested PIP API.","code":""},{"path":"internal-workflow.html","id":"api-feeding","chapter":"2 Internal Workflow","heading":"2.6 API feeding","text":"NOTE: Tony, please finish sections.","code":""},{"path":"internal-workflow.html","id":"packages-interaction","chapter":"2 Internal Workflow","heading":"2.7 Packages interaction","text":"NOTE: Andres, finished sections.","code":""},{"path":"folder-structure.html","id":"folder-structure","chapter":"3 Folder Structure","heading":"3 Folder Structure","text":"Note: Aleksander, please write chapter? Basically, need overview folders root Y drive detailed explanation structure Data folder pipiline folder.","code":""},{"path":"joining-data.html","id":"joining-data","chapter":"4 Joining Data","heading":"4 Joining Data","text":"Since PIP project comprised several databases different domain\nlevels, chapter provides guidelines join data frames correctly.\nfirst thing understand reporting measures PIP (e.g.,\npoverty inequality) uniquely identified four variables: Country,\nyear, domain, welfare type.Country refers independent economies conduct independent household\nsurveys. instance, China Taiwan treated two different\neconomies World Bank, hence PIP, even though \ncriteria people think Taiwan part China.Country refers independent economies conduct independent household\nsurveys. instance, China Taiwan treated two different\neconomies World Bank, hence PIP, even though \ncriteria people think Taiwan part China.Year refers reporting year rather actual calendar years \nsurvey conducted. household surveys like India 2011/2012\nconducted two calendar year, welfare aggregate \ndeflated reporting year, 2011.Year refers reporting year rather actual calendar years \nsurvey conducted. household surveys like India 2011/2012\nconducted two calendar year, welfare aggregate \ndeflated reporting year, 2011.Domain refers smallest geographical disaggregation \npossible deflate line PPP values welfare aggregate \nhousehold survey. criteria determine reporting domain \nhousehold survey still consideration, ideally \nCPI, PPP, population auxiliary data, well household\nsurvey representative level. exceptions \ncriterion like China Philippines, cases explained \ndetailed Section 4.2. today\n(August 16, 2021), country/years reported \nnational domain reported urban/rural domain. However,\nPIP technical infrastructure designed incorporate \ndomain levels , point time, case.Domain refers smallest geographical disaggregation \npossible deflate line PPP values welfare aggregate \nhousehold survey. criteria determine reporting domain \nhousehold survey still consideration, ideally \nCPI, PPP, population auxiliary data, well household\nsurvey representative level. exceptions \ncriterion like China Philippines, cases explained \ndetailed Section 4.2. today\n(August 16, 2021), country/years reported \nnational domain reported urban/rural domain. However,\nPIP technical infrastructure designed incorporate \ndomain levels , point time, case.Finally, welfare type specifies whether welfare aggregate based\nincome consumption. latter case, though households\nsurveys capture expenditure instead, still considered\nconsumption-based surveys.Finally, welfare type specifies whether welfare aggregate based\nincome consumption. latter case, though households\nsurveys capture expenditure instead, still considered\nconsumption-based surveys.challenge joining different data frames PIP four\nvariables uniquely identify reporting measures \navailable PIP data files—\nexception cache files discuss . challenge easily\naddressed clear understanding Price FrameWork (pfw) data\nframe. file contain valuable metadata, also \nconsidered anchor among PIP data.","code":""},{"path":"joining-data.html","id":"pfw-join","chapter":"4 Joining Data","heading":"4.1 The Price FrameWork (pfw) data","text":"always, file can loaded typing,First , notice pfw uniquely identified country code, survey\nyear, survey acronym. reason pfw aims providing \nlink every single household survey auxiliary data.\nSince welfare data stored following naming convention \nInternational Household Survey Network (IHSN), data \nstored according country, survey year, acronym survey, vintage\ncontrol master alternative versions. vintage control master\nalternative version data relevant joining data PIP\nuses, default, recent version.Keep mind PIP estimates reported country, year, domain, \nwelfare type level, last two found either survey\nID unique identifiers pfw. solve problem, pfw data\nmakes use variables welfare_type, aaa_domain, aaa_domain_var.name suggests, welfare_type indicates main welfare aggregate\ntype (.e, income consumption ) variable welfare GMD datasets\ncorrespond survey ID formed concatenating variables\ncountry_code, surveyid_year, survey_acronym. example, \nwelfare_type welfare variable datasets \nCOL_2018_GEIH_V01_M_V03_A_GMD income.prefix aaa variables aaa_domain aaa_domain_var refers \nidentification code auxiliary data. Thus, find \ngdp_domain, cpi_domain, ppp_domain several others. aaa_domain\nvariables contain lower level geographical disaggregation \ncorresponding aaa auxiliary data. three possible levels \ndisaagregation,now, survey auxiliary data broken level 3 (.e.,\nsubnational), important know PIP internal code takes \npossibility account future cases.Depending country, domain level auxiliary data might \ndifferent. Indonesia, instance, CPI domain national, whereas \nPPP domain “urban/rural.”Finally, really important, variables\naaa_domain_var contains name variable GMD dataset uniquely\nidentify household survey corresponding aaa auxiliary data. \nwords, aaa_domain_var contains name variable GMD \nmust used key join GMD aaa. may ask, name \nvariable aaa auxiliary data variable name GMD data\nspecified aaa_domain_var? , . Since domain level \nidentify observations aaa auxiliary data unique, one\nvariable auxiliary data used merge welfare data, aaa_data_level.\nSince process little cumbersome, \n{pipdp} Stata package, \nprocess cleaning GMD databases PIP databases, creates many\naaa_data_level variables needed order make join welfare data\nauxiliary data simpler. can see lines code create \nvariables \nsection\nfile “pipdp_md_clean.ado.”2","code":"\nlibrary(data.table)\npfw <- pipload::pip_load_aux(\"pfw\")\njoyn::is_id(pfw, by = c(\"country_code\", \"surveyid_year\", \"survey_acronym\"))   copies    n percent\n1:      1 1968    100%\n2:  total 1968    100%[1] TRUE\npfw[ country_code    == \"COL\"\n    & surveyid_year  == 2018\n    & survey_acronym == \"GEIH\", # Not necessary since it is the only one\n    unique(welfare_type)][1] \"income\"\npfw[country_code == \"IDN\" & surveyid_year == 2018, .(cpi = unique(cpi_domain), ppp = unique(ppp_domain))]   cpi ppp\n1:   1   2"},{"path":"joining-data.html","id":"joining-data-example","chapter":"4 Joining Data","heading":"4.1.1 Joining data example","text":"Let’s see case Indonesia . pfw says CPI domain \n“national” PPP domain “urban/rural.” means welfare data\njoin auxiliary data two different variables,says name variable welfare data join PPP data \ncalled uban, seem variable name GMD join \nCPI data. name variable missing, indicates \nwelfare data split variable merge CPI data. , \nnational level.","code":"\ndomains <- pfw[country_code == \"IDN\" & surveyid_year == 2018, .(cpi = unique(cpi_domain_var), ppp = unique(ppp_domain_var))][]\nccode <- \"CHN\"\ncpi <- pipload::pip_load_aux(\"cpi\")\nppp <- pipload::pip_load_aux(\"ppp\")\n\nCHN <- pipload::pip_load_data(country = ccode, year = 2015)\n\ndt <- joyn::merge(CHN, cpi, by = c(\"country_code\", \"survey_year\", \"survey_acronym\", \"cpi_data_level\"), match_type = \"m:1\",\n    keep = \"left\")   report  n percent\n1:  x & y 40    100%\n2:  total 40    100%"},{"path":"joining-data.html","id":"special-data-cases","chapter":"4 Joining Data","heading":"4.2 Special data cases","text":"","code":""},{"path":"pfw-chapter.html","id":"pfw-chapter","chapter":"5 Price FrameWork (pfw) data frame","heading":"5 Price FrameWork (pfw) data frame","text":"price framework data frame (pfw) important source technical\nmetadata PIP project, makes pertinent separate\nchapter . general explanation structure pfw can found\nSection 4.1. chapter focuses use \nvariables. Yet, worh repeating things already mentioned Section\n4.1.","code":"\npfw <- pipload::pip_load_aux(\"pfw\")"},{"path":"pfw-chapter.html","id":"variables","chapter":"5 Price FrameWork (pfw) data frame","heading":"5.1 Variables","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"id-vars","chapter":"5 Price FrameWork (pfw) data frame","heading":"ID vars","text":"Variables identification wb_region_code, pcn_region_code,\ncountry_code, ctryname, year, surveyid_year, survey_acronym.main difference wb_region_code pcn_region_code \nformer include geographical regions internally used world bank,\nwhereas latter additional category, “OHI,” High Income\ncountries.difference year surveyid_year … Minh, \nplease explain ?","code":"\njanitor::tabyl(pfw, wb_region_code, pcn_region_code) wb_region_code EAP ECA LAC MNA OHI SAS SSA\n            EAP 144   0   0   0  31   0   0\n            ECA   0 583   0   0 389   0   0\n            LAC   0   0 432   0   0   0   0\n            MNA   0   0   0  65  26   0   0\n            NAC   0   0   0   0  49   0   0\n            SAR   0   0   0   0   0  48   0\n            SSA   0   0   0   0   0   0 201"},{"path":"pfw-chapter.html","id":"altname","chapter":"5 Price FrameWork (pfw) data frame","heading":"altname","text":"Alternative survey name surveys.","code":"\nhead(pfw[altname != \"\", c(\"altname\", \"survey_acronym\")])                      altname survey_acronym\n1:         FSM_2000_PHC_v01_M            CPH\n2: IDN_2002_SUSENAS-FEB_v01_M        SUSENAS\n3: IDN_2003_SUSENAS-FEB_v01_M        SUSENAS\n4: IDN_2004_SUSENAS-FEB_v01_M        SUSENAS\n5: IDN_2005_SUSENAS-FEB_v01_M        SUSENAS\n6: IDN_2006_SUSENAS-FEB_v01_M        SUSENAS"},{"path":"pfw-chapter.html","id":"wbint_link","chapter":"5 Price FrameWork (pfw) data frame","heading":"wbint_link","text":"Minh, please explain ?","code":""},{"path":"pfw-chapter.html","id":"wbext_link","chapter":"5 Price FrameWork (pfw) data frame","heading":"wbext_link","text":"Minh, please explain ?","code":""},{"path":"pfw-chapter.html","id":"alt_link","chapter":"5 Price FrameWork (pfw) data frame","heading":"alt_link","text":"Minh, please explain ?","code":""},{"path":"pfw-chapter.html","id":"surv_title","chapter":"5 Price FrameWork (pfw) data frame","heading":"surv_title","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"surv_producer","chapter":"5 Price FrameWork (pfw) data frame","heading":"surv_producer","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"survey_coverage","chapter":"5 Price FrameWork (pfw) data frame","heading":"survey_coverage","text":"variable represent househol survey coverage. different \ndisaggregation data level.","code":"\njanitor::tabyl(pfw, survey_coverage) survey_coverage    n  percent\n        national 1916 0.973577\n           rural    1 0.000508\n           urban   51 0.025915"},{"path":"pfw-chapter.html","id":"welfare_type","chapter":"5 Price FrameWork (pfw) data frame","heading":"welfare_type","text":"variable contains welfare type main welfare aggregate variable\nsurvey case one. welfare type alternative\nwelfare aggregates found variable oth_welfare1_type.","code":"\njanitor::tabyl(pfw, welfare_type) welfare_type    n percent\n  consumption  807    0.41\n       income 1161    0.59"},{"path":"pfw-chapter.html","id":"use_imputed","chapter":"5 Price FrameWork (pfw) data frame","heading":"use_imputed","text":"Whether welfare aggregate imputed. just countries\nkind data.","code":"\npfw[use_imputed == 1, unique(country_code)][1] \"SOM\" \"SSD\" \"ZWE\""},{"path":"pfw-chapter.html","id":"use_microdata","chapter":"5 Price FrameWork (pfw) data frame","heading":"use_microdata","text":"Whether welfare aggregate vector used PIP directly extracted \nmicrodata without sort aggregation. Mos countries kind\ndata. can see .","code":"\npfw[use_microdata != 1, unique(country_code)] [1] \"AUS\" \"CHN\" \"IDN\" \"JPN\" \"KOR\" \"MNG\" \"MYS\" \"PHL\" \"THA\" \"TWN\" \"ARM\" \"AUT\" \"BEL\" \"BGR\" \"BLR\" \"CHE\"\n[17] \"CZE\" \"DEU\" \"DNK\" \"ESP\" \"EST\" \"FIN\" \"FRA\" \"GBR\" \"GEO\" \"GRC\" \"HRV\" \"HUN\" \"IRL\" \"ITA\" \"KAZ\" \"LTU\"\n[33] \"LUX\" \"LVA\" \"MKD\" \"NLD\" \"NOR\" \"POL\" \"ROU\" \"RUS\" \"SVK\" \"SVN\" \"SWE\" \"TUR\" \"UKR\" \"ARG\" \"BOL\" \"COL\"\n[49] \"CRI\" \"DOM\" \"ECU\" \"GTM\" \"GUY\" \"HND\" \"JAM\" \"LCA\" \"PAN\" \"SLV\" \"TTO\" \"URY\" \"VEN\" \"ARE\" \"DZA\" \"EGY\"\n[65] \"IRN\" \"ISR\" \"JOR\" \"MAR\" \"TUN\" \"BGD\" \"IND\" \"LKA\" \"NPL\" \"BDI\" \"BWA\"\n [ reached getOption(\"max.print\") -- omitted 22 entries ]"},{"path":"pfw-chapter.html","id":"use_bin","chapter":"5 Price FrameWork (pfw) data frame","heading":"use_bin","text":"Whether welfare aggregate aggregated 400 bins microdata \nincorporated PIP repository. case houshold surveys\navailable Luxembourg Data Center\n(LIS). Countries bin data considered\nmicro data technical purposes.","code":"\npfw[use_bin == 1, unique(country_code)] [1] \"AUS\" \"JPN\" \"KOR\" \"TWN\" \"AUT\" \"BEL\" \"CHE\" \"CZE\" \"DEU\" \"DNK\" \"ESP\" \"FIN\" \"FRA\" \"GBR\" \"GRC\" \"HUN\"\n[17] \"IRL\" \"ITA\" \"LUX\" \"NLD\" \"NOR\" \"POL\" \"ROU\" \"SVK\" \"SVN\" \"SWE\" \"ISR\" \"CAN\" \"USA\""},{"path":"pfw-chapter.html","id":"use_groupdata","chapter":"5 Price FrameWork (pfw) data frame","heading":"use_groupdata","text":"Whether welfare aggregate comes grouped data. Information type\ndata available (Datt 1998; Krause 2013; Villaseñor Arnold 1989).\nfollowing countries kind data.","code":"\npfw[use_groupdata == 1, unique(country_code)] [1] \"CHN\" \"IDN\" \"MNG\" \"MYS\" \"PHL\" \"THA\" \"ARM\" \"BGR\" \"BLR\" \"CZE\" \"EST\" \"GEO\" \"HRV\" \"HUN\" \"KAZ\" \"LTU\"\n[17] \"LVA\" \"MKD\" \"POL\" \"ROU\" \"RUS\" \"SVN\" \"TUR\" \"UKR\" \"ARG\" \"BOL\" \"COL\" \"CRI\" \"DOM\" \"ECU\" \"GTM\" \"GUY\"\n[33] \"HND\" \"JAM\" \"LCA\" \"PAN\" \"SLV\" \"TTO\" \"URY\" \"VEN\" \"ARE\" \"DZA\" \"EGY\" \"IRN\" \"JOR\" \"MAR\" \"TUN\" \"BGD\"\n[49] \"IND\" \"LKA\" \"NPL\" \"BDI\" \"BWA\" \"CAF\" \"ETH\" \"GHA\" \"GIN\" \"GNB\" \"KEN\" \"LSO\" \"MDG\" \"MRT\" \"NAM\" \"NER\"\n[65] \"NGA\" \"RWA\" \"SEN\" \"SLE\" \"SWZ\" \"UGA\" \"ZAF\" \"ZMB\" \"ZWE\""},{"path":"pfw-chapter.html","id":"reporting_year","chapter":"5 Price FrameWork (pfw) data frame","heading":"reporting_year","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"survey_comparability","chapter":"5 Price FrameWork (pfw) data frame","heading":"survey_comparability","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"comp_note","chapter":"5 Price FrameWork (pfw) data frame","heading":"comp_note","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"preferable","chapter":"5 Price FrameWork (pfw) data frame","heading":"preferable","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"show_portal","chapter":"5 Price FrameWork (pfw) data frame","heading":"show_portal","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"fieldwork_range","chapter":"5 Price FrameWork (pfw) data frame","heading":"fieldwork_range","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"survey_year","chapter":"5 Price FrameWork (pfw) data frame","heading":"survey_year","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"newref","chapter":"5 Price FrameWork (pfw) data frame","heading":"newref","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"ref_year_des","chapter":"5 Price FrameWork (pfw) data frame","heading":"ref_year_des","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_baseprice","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_baseprice","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_baseprice_note","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_baseprice_note","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_baseprice_des","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_baseprice_des","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_spatial_des","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_spatial_des","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_spatial_var","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_spatial_var","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"cpi_replication","chapter":"5 Price FrameWork (pfw) data frame","heading":"cpi_replication","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"cpi_domain","chapter":"5 Price FrameWork (pfw) data frame","heading":"cpi_domain","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"cpi_domain_var","chapter":"5 Price FrameWork (pfw) data frame","heading":"cpi_domain_var","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_currency_des","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_currency_des","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"ppp_replication","chapter":"5 Price FrameWork (pfw) data frame","heading":"ppp_replication","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"ppp_domain","chapter":"5 Price FrameWork (pfw) data frame","heading":"ppp_domain","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"ppp_domain_var","chapter":"5 Price FrameWork (pfw) data frame","heading":"ppp_domain_var","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_add_temp_des","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_add_temp_des","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_add_temp_var","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_add_temp_var","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_add_spatial_des","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_add_spatial_des","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"wf_add_spatial_var","chapter":"5 Price FrameWork (pfw) data frame","heading":"wf_add_spatial_var","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"tosplit","chapter":"5 Price FrameWork (pfw) data frame","heading":"tosplit","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"tosplit_var","chapter":"5 Price FrameWork (pfw) data frame","heading":"tosplit_var","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"inpovcal","chapter":"5 Price FrameWork (pfw) data frame","heading":"inpovcal","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"oth_welfare1_type","chapter":"5 Price FrameWork (pfw) data frame","heading":"oth_welfare1_type","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"oth_welfare1_var","chapter":"5 Price FrameWork (pfw) data frame","heading":"oth_welfare1_var","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"gdp_domain","chapter":"5 Price FrameWork (pfw) data frame","heading":"gdp_domain","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"pce_domain","chapter":"5 Price FrameWork (pfw) data frame","heading":"pce_domain","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"pop_domain","chapter":"5 Price FrameWork (pfw) data frame","heading":"pop_domain","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"note","chapter":"5 Price FrameWork (pfw) data frame","heading":"Note","text":"blah blah","code":""},{"path":"pfw-chapter.html","id":"pfw_id","chapter":"5 Price FrameWork (pfw) data frame","heading":"pfw_id","text":"blah blah","code":""},{"path":"primus.html","id":"primus","chapter":"6 PRIMUS","heading":"6 PRIMUS","text":"According description Stata repository\nworldbank/primus,PRIMUS system designed facilitate process generating\ninternal estimates World Bank’s poverty indicators reduce time\nneeded resolving discrepancies. workflow management platform \nsubmission, review approval poverty estimates tracking\nfacility capture inputs results estimation process \nfuture reference audits., PRIMUS platform used PovcalNet team approve \nadoption new survey data PovcalNet system.","code":""},{"path":"primus.html","id":"interacting-with-primus","chapter":"6 PRIMUS","heading":"6.1 Interacting with PRIMUS","text":"interaction PRIMUS done different systems, best\nbegin clarifying terms.","code":""},{"path":"primus.html","id":"website-platform","chapter":"6 PRIMUS","heading":"Website platform","text":"PRIMUS can accessed typing\nprimus/ \nbrowser. long ’re connected intranet work fine.\nHowever, issues connecting platform, please send email\nMinh Cong Nguyen, requesting access.database uploaded PRIMUS gets unique transaction ID. ID \nimportant unique dataset unique transaction\n(vintage data). , one particular dataset uploaded \n, get two different transaction IDs. talking \nPoverty GP, better refer transaction ID rather survey (\nleast ) , though may talking country/year, \nactually talking two different transactions. See instance Brazil\n2013.","code":""},{"path":"primus.html","id":"stata-command","chapter":"6 PRIMUS","heading":"Stata command","text":"Poverty GP maintains Stata repository\nworldbank/primus can\ndownload command primus. Right now, official place \ncan access command. now , time refer command, \nuse primus, whereas refer website, use PRIMUS.Please, make sure properly installed computer, following\ninstruction section ??. Basically, need install\nfirst github Stata command E. F.\nHaghishNow, can install primus just typing following StataIn case work, follow instructions section ??\nalternative methods.","code":"net install github, from(\"https://haghish.github.io/github/\")github install worldbank/primus"},{"path":"primus.html","id":"corrections-to-primus-stata-command","chapter":"6 PRIMUS","heading":"Corrections to primus Stata command","text":"primus command maintained Poverty GP, control \nmodifications improvements. best can case need fix \nmodify something command fork repository, clone forked\nrepo computer, check new branch, make modification, \ngenerate pull request master branch original repository. \ndone , make sure send email suggestions \nimprovement Ani Rudra Silwal, copying \nD4G Central Team (Nobuo Yoshida Minh Cong Nguyen).","code":""},{"path":"primus.html","id":"understand-primus","chapter":"6 PRIMUS","heading":"6.2 Understanding PRIMUS","text":"time database uploaded PRIMUS, assigned transaction ID.\nuploading process (right finished), three\nparties–DECDG, DECRG, Poverty GP–evaluate quality new \ncorrected data approve reject system. Depending \ndecision parties, transaction take one three possible\nstatus, pending, approved, rejected.today (2020-11-20), one represents DECRG. , \napproving process might different need changed \nPRIMUS system. Please check.transaction ID pending least one three parties (DECDG,\nDECRG, Poverty GP) approved system. can click \ncheck box PENDING PRIMUS website see surveys \nstatus, can use primus command list ,Notice overall status transaction independent survey ID.\nThus, possible find several transactions country year.\nIndonesia 2017, instance, three transactions, two rejected \none pending.transaction rejected least one three parties rejected \ndatabase. Finally, transaction approved three parties \napproved system.recommend understand basic functionality primus command \nreading help file (type help primus Stata).","code":"qui primus query, overallstatus(PENDING)\nlist transaction_id country year date_modified in 1/`=min(10, _N)'\n     +----------------------------------------------+\n     |              transaction_id   country   year |\n     |----------------------------------------------|\n  1. | TRN-000327173-EAP-IDN-QR48Q       IDN   2017 |\n  2. | TRN-000327173-ECA-DEU-YJYVZ       DEU   1995 |\n  3. | TRN-000327173-ECA-DEU-2P4DR       DEU   2002 |\n  4. | TRN-000327173-ECA-DEU-LJN8R       DEU   2003 |\n  5. | TRN-000327173-ECA-DEU-ZSN9J       DEU   2005 |\n     |----------------------------------------------|\n  6. | TRN-000327173-ECA-DEU-UBS7M       DEU   2008 |\n  7. | TRN-000327173-ECA-DEU-41TOU       DEU   2009 |\n  8. | TRN-000327173-EAP-AUS-KKZ2E       AUS   2004 |\n     +----------------------------------------------+qui primus query, country(IDN) year(2017)\nlist transaction_id overall_status date_modified in 1/`=min(10, _N)'\n     +--------------------------------------------------+\n     |              transaction_id        date_modified |\n     |--------------------------------------------------|\n  1. | TRN-000104674-EAP-IDN-8R9IF   23may2018 15:28:47 |\n  2. | TRN-000327173-EAP-IDN-TYA1A   23may2018 23:57:27 |\n  3. | TRN-000327173-EAP-IDN-QR48Q   24may2018 00:27:33 |\n     +--------------------------------------------------+"},{"path":"primus.html","id":"checking-primus-estimates","chapter":"6 PRIMUS","heading":"6.3 Checking PRIMUS estimates","text":"real first step check quality recently uploaded data \nPRIMUS download basic estimates data compare \n. need calculate compare estimates available \nPRIMUS mean PPP, poverty headcount, Gini index.primus command allows us download estimates transaction,\ndone one one. Fortunately, pcn command downloads \nestimates pending transactions us properly stores \nfolder p:\\01.PovcalNet\\03.QA\\02.PRIMUS\\pending\\ 🎉\n🎉 . need type,addition, pcn checks date ’re downloading estimates\nkeeps transactions uploaded next spring \nannual-meetings release. instance, assume today, 2020-11-20, want\nsee estimates pending transactions PRIMUS. Since annual meetings\ntake place around September, pcn assumes interested estimates\nSpring-meetings release, around March next year. Thus, filter\nresults primus, keeping transactions uploaded\nNovember 2020. Now likely PRIMUS system opened\nuploading new data November, usually opens around December \nJuly. Thus, likely find error saying\npending data PRIMUS combination country/years selected.can load recently-downloaded estimates typing,Now, check whether new estimates make sense. way \nfollow -file,\np:\\01.PovcalNet\\03.QA\\02.PRIMUS\\pending\\2020_SM\\estimates\\checks\\comparisons_wrk_data..need check estimates working data (wrk) \nsuggested -file . PovcalNet System now fully integrated\ndatalibweb system, CPI, PPP, microdata always \n. best can stage make sure estimates PRIMUS\nmake sense country level.","code":"pcn primus pending, down(estimates)pcn primus pending, load(estimates)"},{"path":"primus.html","id":"approve-primus","chapter":"6 PRIMUS","heading":"6.4 Confirming and approving data in PRIMUS","text":"checked estimates pending transactions make sense, \nneed approve . explained section 6.2, \napproval PRIMUS requires consent three parties. PovcalNet team \nresponsibility approve behalf two , DECDG DECRG. \nprocess can easily done code , can found file,\np:\\01.PovcalNet\\03.QA\\02.PRIMUS\\pending\\2020_SM\\approve\\primus_approve..Basically, need file.Modify local excl case want approve one several\ncountries.Modify local filtdate select date want \napprove transactions.Make sure least two people approve. One behalf “povcalnet” (\nalias used DECRG) another behalf “decdg.”PRIMUS double-confirmation process, need “confirm” \n“approve” transaction. , need change option\ndecision() approved confirmed.unknown reason, PRIMUS system accept approval \ntransactions. happens , need talk Minh Cong\nNguyen, can approval manually.","code":"/*==================================================\n0: Program set up\n==================================================*/\nversion 14\ndrop _all\n\n*---------- Modify this\nlocal excl = \"BRA SOM SSD\" // countries to exclude \nlocal excl = \"\" // countries to exclude \n\n/*==================================================\nLoad data\n==================================================*/\n\nprimus query, overalls(pending)\n//------------Cut off date\nlocal filtdate = \"2019-12-01\" // filter date (december last year)\nlocal filtdate = \"2020-02-18\" // filter date (surveys uploaded by Minh)\nkeep if  date_modified >= clock(\"`filtdate'\", \"YMD\")\n\n//------------Select username\nif (lower(\"`c(username)'\") == \"wb424681\") {\n  local dep = \"povcalnet\"\n}\nelse if (lower(\"`c(username)'\") == \"wb384996\") {\n  local dep = \"decdg\"\n}\nelse {\n  noi disp in red \"you don't have rights to run this code\"\n  break\n}\n\ntab `dep'\nkeep if `dep' == \"PENDING\"\n\nif (\"`excl'\" != \"\") {\n  local excl: subinstr local excl \" \" \"|\", all\n  drop if regexm(\"`country'\", \"`excl'\") \n}\n\n/*=================================================\nApprove (Do NOT modify)\n==================================================*/\n\nlocal n = _N\npreserve \nqui foreach i of numlist 1/`n' {\n  restore, preserve\n  local country = country[`i']\n  local year    = year[`i']\n  local id      = transaction_id[`i']\n  \n  noi disp in y \"primus action, tranxid(`id') decision(approved)\"\n  cap noi primus action, tranxid(`id') decision(approved)\n  if (_rc) noi disp \"problem with `id'\"\n}"},{"path":"welfare-data.html","id":"welfare-data","chapter":"7 Welfare data","heading":"7 Welfare data","text":"blah blah blah","code":""},{"path":"welfare-data.html","id":"welfare-origin-of-data","chapter":"7 Welfare data","heading":"7.1 Origin of data","text":"blah","code":""},{"path":"welfare-data.html","id":"from-gmd-to-pip","chapter":"7 Welfare data","heading":"7.2 From GMD to PIP ({pipdp} package)","text":"blah","code":""},{"path":"welfare-data.html","id":"survey-id-nomenclature","chapter":"7 Welfare data","heading":"7.3 Survey ID nomenclature","text":"household surveys PIP repository stored following naming\nconvention International Household Survey Network\n(IHSN) archiving managing\ndata. structure can generalized \nfollows:,CCC refers 3 letter ISO country codeYYYY refers survey year data collection startedSSSS refers survey acronym (e.g., LSMS, CWIQ, HBS, etc.)vNN version vintage raw/master data followed M \nalternative/adapted data followed . first version\nalways v01, newer version available named\nsequentially (e.g. v02, v03, etc.). Note new version \navailable, previous ones must still kept.TYPE refers collection name. case PIP data, type \nprecisely, PIP, aware several types \ndatalibweb collection. instance, Global Monitoring Database uses\nGMD; South Asia region uses SARMD; LAC region uses\nSEDLAC.MODULE refers module collection. part survey ID\navailable file level, folder (.e, survey)\nlevel. Since folder structure created survey level, \nplace survey ID include module survey. However,\nwithin single survey, may find different modules, specified\nname file. case PIP, module survey \ndivided two: PIP tool GMD module. PIP tool \nPC, TB, SOL (forthcoming), stand one PIP systems,\nPoverty Calculator, Table Baker (Maker), Statistics OnLine. GMD\nmodule, refers original module GMD collection, module\n, GPWG, HIST, BIN.example, recent version harmonized Pakistani Household\nSurvey 2015, refer survey ID\nPAK_2015_PSLM_v01_M_v02_A_PIP. case, PSLM refers acronym \nPakistan Social Living Standards Measurement Survey. v01_M means \nversion raw data changed since released v02_A means\nrecent version alternative version 02.2","code":"CCC_YYYY_SSSS_ vNN_M_vNN_A_TYPE_MODULE"},{"path":"auxiliary-data.html","id":"auxiliary-data","chapter":"8 Auxiliary data","heading":"8 Auxiliary data","text":"said Section 2.3, auxiliary data data\nused temporally deflate line welfare data, objective \ngetting poverty estimates comparable time, across countries, , \nimportantly, able estimate regional global estimates. Yet,\nauxiliary data also refers metadata functional qualitative\ninformation. Functional information used internal\ncalculations time comparability surveys availability. Qualitative\ninformation just useful information affect, neither depend ,\nquantitative data. primary collected made available end user.explain Chapter 3, auxiliary data stored \n\"y:/PIP-Data/_aux/\".naming convention subfolders inside _aux directory useful \nauxiliary data commonly referred technical processes \nconvention rather actual name. instance Gross Domestic Product \nPurchasing Power Parity better known gdp ppp, respectively. Yet,\nmeasures national population consumption also make use \nconventions.chapter learn everything related files \nstore auxiliary data. Notice chapter structured files rather \nmeasures types auxiliary data may find one\nmeasure one file.R package manages auxiliary data {pipaux}.explained Chapter 3, within folder \nauxiliary file, find, minimum, _vintage folder, one xxx.fst,\none xxx.dta file, one xxx_datasignature.txt , xxx stands \nname file.","code":"y:/PIP-Data/_aux/\n+-- country_list\n+-- cpi\n+-- dlw\n+-- gdm\n+-- gdp\n+-- maddison\n+-- pce\n+-- pfw\n+-- pop\n+-- ppp\n+-- sna\n\\-- weo"},{"path":"auxiliary-data.html","id":"population","chapter":"8 Auxiliary data","heading":"8.1 Population","text":"","code":""},{"path":"auxiliary-data.html","id":"original-data","chapter":"8 Auxiliary data","heading":"8.1.1 Original data","text":"Everything related population data placed folder\ny:\\PIP-Data\\_aux\\pop\\. hereafter (./).population data come one two different sources. WDI internal\nfile provided member DECDG team. Ideally, population data \ndownloaded WDI, sometimes recent data available \nuploaded yet, needs collected internally DECDG. now\n(August 16, 2021), DECDG focal point provide \npopulation data Emi Suzuki. just need \nsend email, provide data .data provided DECDG, stored folder\n./raw_data. original excel file must placed without modification \nfolder ./raw_data/original. , file copied one level \nfolder ./raw_data name population_country_yyyy-mm-dd.xlsx \nyyyy-mm-dd refers official release date population data. Notice\ncountries PSE, KWT SXM, years population data missing\nDECDG main file hence WDI. complement main file \nadditional file shared Emi assure complete coverage. file contains\nhistorical data need updated every year. additional file\nname convention population_missing_yyyy-mm-dd.xlsx follow\nprocess population_country file. files \ncorresponding place, can update ./pop.fst file typing\npipaux::pip_pop_update(src = \"decdg\").data comes directly WDI, just need update file\n./pop.fst typing pipaux::pip_pop_update(src = \"wdi\"). worth\nmentioning population codes used WDI “SP.POP.TOTL,”\n“SP.RUR.TOTL,” “SP.URB.TOTL,” total population, rural population,\nurban population, respectively. case PIP begins using\nsubnational population, new set WDI codes added R script\n\npipaux::pip_pop_update().","code":""},{"path":"auxiliary-data.html","id":"data-structure","chapter":"8 Auxiliary data","heading":"8.1.2 Data structure","text":"Population data loaded typing either pipload::pip_load_aux(\"pop\") \npipaux::pip_pop(\"load\"). highly recommend former, {pipload} \nintended R package loading PIP data.","code":"\npop <- pipload::pip_load_aux(\"pop\")\nhead(pop)   country_code year pop_data_level     pop  pop_domain\n1:          ABW 1960       national   54211    national\n2:          ABW 1960          rural   26685 urban/rural\n3:          ABW 1960          urban   27526 urban/rural\n4:          AFG 1960       national 8996973    national\n5:          AFG 1960          rural 8241137 urban/rural\n6:          AFG 1960          urban  755836 urban/rural"},{"path":"auxiliary-data.html","id":"national-accounts","chapter":"8 Auxiliary data","heading":"8.2 National Accounts","text":"National accounts account economic development country \naggregate macroeconomic level. measure thus useful interpolate\nextrapolate microeconomic measures mean welfare aggregate poverty\nheadcount household surveys available. National accounts work \nproxy economic development present household\nsurveys available.two main types national accounts, Household Final Consumption\nExpenditure (HFCE) Gross Domestic Product (GDP)—real per capita\nterms. Please refer Section\n5.3\n(World Bank 2021) understand usage national\naccounts data.","code":""},{"path":"auxiliary-data.html","id":"gdp","chapter":"8 Auxiliary data","heading":"8.2.1 GDP","text":"explained Section\n5.3\n(World Bank 2021), three sources GDP\ndata, one particular cases. integration \nsources GDP data performed pipaux::pip_gdp_update(), ’ll need \nmanually download store data WEO data special\ncases. national accounts series WDI GDP per capita  [series code:\nNY.GDP.PCAP.KD]. series constant 2010 US$.recent version WEO data downloaded World\nEconomic Outlook\nDatabases\nIMF.org website saved .xls file <maindir>/_aux/weo/. \nfilename following structure WEO_<YYYY-DD-MM>.xls. Due \npotential file corruption file must opened re-saved can \nupdated pip_gdp_weo(), internal function fo\npipaux::pip_gdp_update(). Hopefully future IMF stop using \n`.xls` file ’s really xls.Note: explanation special cases provided Samuel.","code":""},{"path":"auxiliary-data.html","id":"consumption-pce","chapter":"8 Auxiliary data","heading":"8.2.2 Consumption (PCE)","text":"Private Consumption Expenditure (pce) gathered WDI, exception\nspecial cases. case GDP, special cases treated \nway PCE. need execute function\npipaux::pip_pce_update() update PCE data. HFCE per capita [series code:\nNE.CON.PRVT.PC.KD] (Prydz et al. 2019). series \nconstant 2010 US$.","code":""},{"path":"auxiliary-data.html","id":"national-accounts-special-cases","chapter":"8 Auxiliary data","heading":"8.2.3 National Accounts, Special Cases","text":"Special national accounts used lining poverty estimates \nfollowing cases3:National accounts data unavailable latest version WDI.\ncases, national accounts data obtained, order preference,\nlatest version WEO, latest version MPD. example,\nentire series GDP per capita Taiwan, China Somalia \nmissing WDI, WEO\nseries used instead.National accounts data unavailable latest version WDI.cases, national accounts data obtained, order preference,\nlatest version WEO, latest version MPD. example,\nentire series GDP per capita Taiwan, China Somalia \nmissing WDI, WEO\nseries used instead.National accounts data incomplete latest version WDI.\ncases national accounts data available WDI\nhistorical recent years. cases, national accounts data\nWDI chained backward forward using growth rates WEO \nMPD, order. example, GDP per capita South Sudan (2016-2019)\nbased growth rate GDP per capita WEO. GDP per capita data\nLiberia 1999 based growth rate GDP per capita \nMPD.National accounts data incomplete latest version WDI.cases national accounts data available WDI\nhistorical recent years. cases, national accounts data\nWDI chained backward forward using growth rates WEO \nMPD, order. example, GDP per capita South Sudan (2016-2019)\nbased growth rate GDP per capita WEO. GDP per capita data\nLiberia 1999 based growth rate GDP per capita \nMPD.available national accounts data official sources (e.g. WDI, WEO,\nMPD) considered quality issues.\ncase Syria. Supplementary national accounts data \nobtained sources, including research\npapers national statistical offices. GDP per capita series Syria (\n2010 2019) research\npapers---@kostialSyriaConflictEconomy2016Gobat (2011-2015) \nDevadas, Elbadawi, Loayza (2019) (2016-2019)—chained backward\ngrowth rates GDP per capita WEO. See\nP:\\01.PovcalNet\\03.QA\\04.NationalAccounts\\data\\NAS special_2021-01-14\ndetails implemented.available national accounts data official sources (e.g. WDI, WEO,\nMPD) considered quality issues.case Syria. Supplementary national accounts data \nobtained sources, including research\npapers national statistical offices. GDP per capita series Syria (\n2010 2019) research\npapers---@kostialSyriaConflictEconomy2016Gobat (2011-2015) \nDevadas, Elbadawi, Loayza (2019) (2016-2019)—chained backward\ngrowth rates GDP per capita WEO. See\nP:\\01.PovcalNet\\03.QA\\04.NationalAccounts\\data\\NAS special_2021-01-14\ndetails implemented.National accounts data need adjusted purposes global\npoverty monitoring.\ncase India. Growth rates national accounts data rural\nurban India 2014, precisely HFCE (formerly PCE) per capita \nWDI, adjusted pass-rate 67%, described Section 5\nCastaneda Aguilar et al. (2020). See\nP:\\01.PovcalNet\\03.QA\\04.NationalAccounts\\data\\NAS special_2021-01-14\ndetails implemented.National accounts data need adjusted purposes global\npoverty monitoring.case India. Growth rates national accounts data rural\nurban India 2014, precisely HFCE (formerly PCE) per capita \nWDI, adjusted pass-rate 67%, described Section 5\nCastaneda Aguilar et al. (2020). See\nP:\\01.PovcalNet\\03.QA\\04.NationalAccounts\\data\\NAS special_2021-01-14\ndetails implemented.","code":""},{"path":"auxiliary-data.html","id":"cpi","chapter":"8 Auxiliary data","heading":"8.3 CPI","text":"","code":""},{"path":"auxiliary-data.html","id":"raw-data","chapter":"8 Auxiliary data","heading":"8.3.1 Raw data","text":"Note: Minh explain CPI data collected organized dlw\nfolders.","code":""},{"path":"auxiliary-data.html","id":"vintage-control","chapter":"8 Auxiliary data","heading":"8.3.2 Vintage control","text":"Vintage control CPI data comes similar fashion welfare data,\nCPI_vXX_M_vXX_A, vXX_M refers version master raw\ndata, vXX_A refers alternative version.Every year, around November-December, PIP CPI data updated \nrecent version IMF CPI data, comes information \nrecent year available changes/fixes/additions previous years \ncountry. happens, master version CPI ID increased\none unit data saved. today, current ID CPI_v05_M_v01_A.\ndata modified rolling year, alternative version\nCPI ID increased one unit.","code":""},{"path":"auxiliary-data.html","id":"data-structure-1","chapter":"8 Auxiliary data","heading":"8.3.3 Data structure","text":"load CPI data using pipload::pip_load_aux(\"cpi\"), data get\nalready cleaned use PIP workflow, slightly\ndifferent original CPI data stored datalibweb servers. , \nway CPI data used referred datalibweb different way \nused PIP even though achive purpose.important variable CPI data , surprisingly, cpi. \nvariable however, available original CPI data dlw. \noriginal name variable comes form cpiYYYY, YYYY refers\nbase year CPI, turn depends collection year \nPPP. Today, variable thus “cpi2011.” name \nvariable stored pipaux.cpivar object zzz.R file \n{pipaux} package. supdate option getOption(\"pipaux.cpivar\"),\nguaranteing pipaux::pip_cpi_update() uses right variable \nupdating CPI data.Another important variable CPI dataframe change_cpiYYYY, YYYY\nstands base year CPI. Since version control CPI data\ndepend individual changes CPI series country \nrelease new data IMF additional modifications \nPoverty GP, variable change_cpiYYYY tracks changes CPI \ncountry/year/survey respect previous version. useful\nneed identify changes output measures like poverty rates \ndepend deflation. One possible source difference CPI \nvariable help identify whether number interest change\nCPI changed.","code":""},{"path":"auxiliary-data.html","id":"ppp","chapter":"8 Auxiliary data","heading":"8.4 PPP","text":"","code":""},{"path":"auxiliary-data.html","id":"original-data-1","chapter":"8 Auxiliary data","heading":"8.4.1 Original data","text":"Note: Minh explain PPP data collected organized dlw\nfolders.name variables wide-format file follow structure,\nppp_YYYY_vX_vY. ,YYYY: refers ICP round.YYYY: refers ICP round.vX: refers version release.vX: refers version release.vY: refers adaptation release. , v1 original\ndata, whereas v2 first adaptation estimates release.vY: refers adaptation release. , v1 original\ndata, whereas v2 first adaptation estimates release.","code":""},{"path":"auxiliary-data.html","id":"data-structure-2","chapter":"8 Auxiliary data","heading":"8.4.2 Data structure","text":"PPP data available typing, pipload::pip_load_aux(\"ppp\"). expected,\ndata get already cleaned use PIP workflow, \nslightly different original PPP data stored datalibweb\nservers. important difference PIP data frame \ndatalibweb data frame rectangular structure. PIP data long format,\nwhereas datalibweb data wide format.reason PPP data long format PIP countries,\n, use different PPP year rest countries. Instead \nusing different variable calculations specific countries, \nuse variable countries filter corresponding\nobservations country using metadata Price Framework database.PPP data country/ppp year/data_level/release version/adapation\nversion level. Yet, several filters always applied data can\nused. Ultimately, data frame country/data_level level \nused properly. general rule, filter must done selecting \nrecent release_version recent adaptation_version year.\ncan just filter PPP year want work . order make\nprocess even easier created variables ppp_default \nppp_default_by_year, dummy variables filter data. keep \nobservations ppp_default == 1 get current PPP used \nPIP calculations. use ppp_default_by_year == 1, get default\nversion used PPP year. useful case want make\ncomparisons PPP releases. two variables created function\npipaux::pip_ppp_clean() , particular \nlines.","code":""},{"path":"auxiliary-data.html","id":"price-framework-pfw","chapter":"8 Auxiliary data","heading":"8.5 Price FrameWork (PFW)","text":"blah","code":""},{"path":"auxiliary-data.html","id":"original-data-2","chapter":"8 Auxiliary data","heading":"8.5.1 Original data","text":"asds","code":""},{"path":"auxiliary-data.html","id":"abbreviations","chapter":"8 Auxiliary data","heading":"8.6 Abbreviations","text":"HFCE – final consumption expenditureMDP – Maddison Project DatabasePCE – private consumption expenditureWDI – World Development IndicatorsWEO – World Economic Outlook","code":""},{"path":"pcpipeline.html","id":"pcpipeline","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9 Poverty Calculator Pipeline (pre-computed estimations)","text":"Poverty Calculator Pipeline–hereafter, rest chapter, pipeline–technical procedure calculate pre-computed (statitic) estimations PIP project. estimations two main purposes:provide user instantaneous information distributive measures household surveys PIP repository depend value poverty line (e.g. mean income, quantiles). Avoiding thus need re-computation case PovcalNet measures.provide necessary inputs PIP API.chapter walks folder structure folder, main R script, _targets.R, complete partial execution script. Also, provides tips debugging.","code":""},{"path":"pcpipeline.html","id":"folder-structure-1","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.1 Folder structure","text":"pipeline hosted Github repository PIP-Technical-Team/pip_ingestion_pipeline. root repo find series files folders.","code":"\n# > +-- batch > +-- pip_ingestion_pipeline.Rproj > +-- R > +-- README.md > +-- renv > +-- renv.lock >\n# +-- run.R > +-- _packages.R > \\-- _targets > \\-- _targets.R"},{"path":"pcpipeline.html","id":"folders","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Folders","text":"R contains long R functions used pipelineR contains long R functions used pipelinebatch script timing execution pipeline. folder probably removedbatch script timing execution pipeline. folder probably removed_targets folder objects created pipeline. don’t need look inside content managed targets package._targets folder objects created pipeline. don’t need look inside content managed targets package.renv folder reproducible environment.renv folder reproducible environment.","code":""},{"path":"pcpipeline.html","id":"files","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Files","text":"_packages.R created targets::tar_renv(). modify manually._packages.R created targets::tar_renv(). modify manually._targets.R contains pipeline. important file._targets.R contains pipeline. important file.","code":""},{"path":"pcpipeline.html","id":"prerequisites","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.2 Prerequisites","text":"start working pipeline, need make sure following PIP packages.Note 1: notice instructions contain suffixes like @development. specify branch particular package need use. Ideally, packages use master branch; however, possible end development process.Note 2: update packages developed PIP team, make sure always increased version package using function usethis::use_version(). Even change package small, need increased version package. Otherwise, targets won’t execute sections pipeline run functions changed.case renv working , may need install packages mentioned _packages.R script root folder. Also, make sure install recent version targets tarchetypes packages.","code":"\nremotes::install_github(\"PIP-Technical-Team/pipdm@development\")\nremotes::install_github(\"PIP-Technical-Team/pipload@development\")\nremotes::install_github(\"PIP-Technical-Team/wbpip@halfmedian_spl\")\ninstall.packages(\"joyn\")"},{"path":"pcpipeline.html","id":"structure-of-the-_targets.r-file","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.3 Structure of the _targets.R file","text":"Even thought pipeline script looks like regular R script, structured specific way order make work {targets} package. fact, notice must called _targets.R root project. highly recommended read entire targets manual fully understand works. often referring manual order expand particular targets’ concept.","code":""},{"path":"pcpipeline.html","id":"start-up","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Start up","text":"first part pipeline sets environment. process involve,loading targets tarchetypes packages;creating default values like directories, time stamps, survey reference years boundaries, compression level .fst files, etc.;executing tar_option_set() set option targets. packages imports two particularly important options track changes package dependencies. can read sections Loading configuring R packages Packages-based invalidation targets manual;attaching packages functions project running source('_packages.R') source('R/_common.R').","code":""},{"path":"pcpipeline.html","id":"step-1-small-functions","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Step 1: small functions","text":"According section Functions pipelines targets manual, recommend use functions rather expressions executions. Presumably, reason targets track changes functions expressions. Thus, scripts section defines small functions executed along pipeline. section , scripts source('R/_common.R') loads longer functions. Yet, keep mind 'R/_common.R' used previous version pipeline targets implemented. Now, function 'R/_common.R' included pipdm package.","code":""},{"path":"pcpipeline.html","id":"step-2-preparing-the-data","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Step 2: preparing the data","text":"section used longer previous versions pipeline used identify auxiliary data, load PIP microdata inventory, create cache files. now identifies auxiliary data.","code":""},{"path":"pcpipeline.html","id":"step-3-the-actual-pipeline","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Step 3: The actual pipeline","text":"Although better explained next section, overall order pipeline follows:Load necessary data (, auxiliary data inventories), create cache fie created yet.Load necessary data (, auxiliary data inventories), create cache fie created yet.Calculate means LCUCalculate means LCUCrate deflated survey mean (DSM) tableCrate deflated survey mean (DSM) tableCalculate reference year table (aka., interpolated means table)Calculate reference year table (aka., interpolated means table)Calculate distributional statsCalculate distributional statsCreate output tables\njoin survey mean table dist table\njoin reference year table dist table\ncoverage table aggregate population regional level table\nCreate output tablesjoin survey mean table dist tablejoin survey mean table dist tablejoin reference year table dist tablejoin reference year table dist tablecoverage table aggregate population regional level tablecoverage table aggregate population regional level tableClean save.Clean save.","code":""},{"path":"pcpipeline.html","id":"understanding-the-pipeline","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.4 Understanding the pipeline","text":"must understand targets package works, also targets Poverty Calculator Pipeline created. former, can read targets manual. latter, start making distinction different types targets.targets terminology, two kinds targets, stems branches. Stems unitary targets. , target one single R object. Branches, hand, targets contain several objects subtargets inside (can learn chapter Dynamic branching targets manual). see use type targets talk use cache files.","code":""},{"path":"pcpipeline.html","id":"stem-targets","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Stem targets","text":"two ways create stem targets: either using tar_target() using tar_map() tarchetypes package. tar_map() function allows create stem targets iteratively. See instance creation targets auxiliary data:tar_map() takes values data frame aux_tb created Step 2: preparing data creates two type targets. First, creates target aux_dir contains paths auxiliary files, available column auxfiles aux_tb. done creating internal target within tar_map() using argument format = \"file\". process lets targets know objects loaded file created inside pc pipeline., tar_map() uses column auxname aux_tb name targets contain auxiliary files. target prefixed word “aux.” add argument file_to_load pipload::pip_load_aux, can let targets know file paths defined target aux_dir used create targets prefixed “aux,” actual targets. example, need use population data frame inside pc pipeline, ’d use target aux_pop, corresponding file path aux_dir. way, original file referenced aux_dir changes, targets depend aux_pop run .","code":"\ntar_map(\n  values = aux_tb, \n  names  = \"auxname\", \n  \n  # create dynamic name\n  tar_target(\n    aux_dir,\n    auxfiles, \n    format = \"file\"\n  ), \n  tar_target(\n    aux,\n    pipload::pip_load_aux(file_to_load = aux_dir,\n                          apply_label = FALSE)\n  )\n  \n)"},{"path":"pcpipeline.html","id":"branches-targets","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Branches targets","text":"Let’s think branch target like…explained , branch targets targets made many “subtargets” follow particular pattern. targets created pc pipeline branch targets need execute procedure every cache file. done internally single one, lose tracking features targets. Additionally, created stem target every cache file, result, output file, impossible visualize difficult code. Hence, branch targets best option.following example illustrates works,code illustrates several things. divided steps, last step (step E) part code branch target created. Yet, important understand previous steps.step create target cache_inventory_dir, merely file path contains cache inventory. Notice returned function entered directly target. Since file path, need add argument format = \"file\" let targets know input data. step B load cache inventory file target cache_inventory providing target “path” created step . file several columns. One contains file path every single cache file PIP network drive. single column extracted cache inventory step C. , step D, file path declared input, using convenient function tar_files(), creating thus new target, cache_dir. Finally, create branch target cache cache files loading file. iteratively, parse cache_dir target path argument function fst::read_fst() pattern = map() argument tar_target() function. end, need specify output iteration stored list, using argument iteration = \"list\".basic logic branch targets vector list iterate parsed function’s argument pattern = map() argument tar_target() function. similar purrr::map()Note: iterating one vector list, need (1) separate commas map() part argument (See example code ). (2) make sure vectors lists length. remove NULL NA values target. (3) make sure sort output targets loose correspondence targets.","code":"# step A\ntar_target(\n  cache_inventory_dir, \n  cache_inventory_path(),\n  format = \"file\"\n),\n\n# step B\ntar_target(\n  cache_inventory, \n  {\n    x <- fst::read_fst(cache_inventory_dir, \n                       as.data.table = TRUE)\n  },\n),\n\n# step C\ntar_target(cache_files,\n           get_cache_files(cache_inventory)),\n\n# step D\ntar_files(cache_dir, cache_files),\n\n# step E\ntar_target(cache, \n           fst::read_fst(path = cache_dir, \n                         as.data.table = TRUE), \n           pattern = map(cache_dir), \n           iteration = \"list\")\n# Example of creating branch target using several lists to iterate through.\ntar_target(name = dl_dist_stats, command = db_compute_dist_stats(dt = cache, mean = dl_mean, pop = aux_pop,\n    cache_id = cache_ids), pattern = map(cache, dl_mean, cache_ids), iteration = \"list\")"},{"path":"pcpipeline.html","id":"creating-the-cache-files","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Creating the cache files","text":"following code illustrates creation cache files:important understand part pc pipeline thoroughly cache files used created Step 2: preparing data rather . Now, integrated pc pipeline, also possible execute creation cache files independently rest pipeline, following instructions [Executing _targets.R file].first target, pipeline_inventory just inner join pip inventory dataset price framework (pfw) file, make sure include pfw says. data set also contains lot useful information create cache files. Note commented line target filter pipeline inventory information IDN, 2015. need update specific cache files, must add proper filtering condition .second target, status_cache_files_creation, create cache files notice returning value function pipdm::create_cache_file() cache file per-se, list status creation process. creation particular file fails, stop iteration creates cache files. end process, returns list creation status cache file. Notice function pipdm::create_cache_file() requires CPI PPP auxiliary data. variable welfare_ppp, welfare aggregate 2011 PPP values, added cache files. FInally, importantly, argument force = TRUE ensures even cache file already exists, modified. important require additional features cache file ones currently . set TRUE, replace file network drive listed pipeline_inventory. set FALSE, files pipeline_inventory -cache folder- created. Use option need add new features cache data, testing need surveys new features.","code":"tar_target(pipeline_inventory, {\n  x <- pipdm::db_filter_inventory(\n    dt = pip_inventory,\n    pfw_table = aux_pfw)\n  \n  # Uncomment for specific countries\n  # x <- x[country_code == 'IDN' & surveyid_year == 2015]\n}\n),\ntar_target(status_cache_files_creation, \n           pipdm::create_cache_file(\n             pipeline_inventory = pipeline_inventory,\n             pip_data_dir       = PIP_DATA_DIR,\n             tool               = \"PC\",\n             cache_svy_dir      = CACHE_SVY_DIR,\n             compress           = FST_COMP_LVL,\n             force              = TRUE,\n             verbose            = FALSE,\n             cpi_dt             = aux_cpi,\n             ppp_dt             = aux_ppp)\n)"},{"path":"pcpipeline.html","id":"understanding-pipdm-functions","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.5 Understanding {pipdm} functions","text":"pipdm package backbone pc pipeline. charge executing functions wbpip consolidate new DataBases. many functions pipdm prefixed “db_.”","code":""},{"path":"pcpipeline.html","id":"internal-structure-of-pipdm-functions","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.5.1 Internal structure of {pipdm} functions","text":"main objective pipdm execute functions wbpip calculations build data frames. today (2021-08-16), process little intricate.Let’s take example estimating distributive measures pipeline. image shows least three intermediate function levels db_compute_dist_stats() function, directly executed pc pipeline, wbpip::md_compute_dist_stats(), makes calculations. Also, notice functions general regards output. higher level function specific enough retrieve one measure, Gini coefficient, median, quantiles distribution. need add modify one particular distributive measure, must functions inside wbpip::md_compute_dist_stats(), making sure new output mess execution intermediate functions results get db_compute_dist_stats().long chain functions inflexible makes debugging difficult. , need make modification, first identify chain execution pipdm function modify, make sure changes affect output format may break execution chain. also good example structure needs improved.","code":""},{"path":"pcpipeline.html","id":"updating-pipdm-or-any-other-pip-package","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.5.2 Updating {pipdm} (or any other PIP package)","text":"explained , need modify function pipdm wbpip, need make sure output conflict execution chain. Additionally, update packages developed PIP team, make sure always increased version package using function usethis::use_version(). Even change package small, need increase version package. Otherwise, targets won’t execute sections pipeline run functions changed. Finally explained Prerequisites, working branch different master, make sure install version package running pipeline.","code":""},{"path":"pcpipeline.html","id":"executing-the-_targets.r-file","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.6 Executing the _targets.R file","text":".Rprofile root directory makes sure targets tarchetypes loaded project started. whole pipeline execution might time consuming still needs load data network drive. use desktop remote connection execution might faster running locally, still time consuming. , advisable execute targets directly affected changes manually check everything looks ok. , can execute entire code confidently leave running overnight.order execute whole pipeline, need type directive tar_make() console. want execute one target, type name target directive, e.g., tar_make(dl_dist_stats). Keep mind inputs prior targets objective target changed, targets executed first.","code":""},{"path":"pcpipeline.html","id":"debugging","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"9.7 Debugging","text":"Debugging targets easy. Yet, two ways . first way provided chapter Debugging Targets Manual. provides clear instruction debug still pipeline, case don’t find method flexible dig deep enough problem. Alternatively, debug stepping pipeline little bit gain flexibility, described .Debugging needed one two cases: one, got error running pipeline tar_make() , two, results odd. either case, probably idea–though always–problem . problem error execution pipeline, targets printed messages usually informative.","code":""},{"path":"pcpipeline.html","id":"debugging-stem-targets","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Debugging stem targets","text":"Let’s see simple example. Assume problem target dt_dist_stats, created executing function db_create_dist_table pipdm package. Since problem , targets inputs necessary create dt_dist_stats available _targets/ data store. , can load using tar_load() execute function debugging mode. Like ,Note must use :: environment targets runs different global environment, might attached libraries.","code":"\ntar_load(dl_dist_stats)\ntar_load(svy_mean_ppp_table)\ntar_load(cache_inventory)\n\ndebugonce(pipdm::db_create_dist_table)\npipdm::db_create_dist_table(dl = dl_dist_stats, dsm_table = svy_mean_ppp_table, crr_inv = cache_inventory)"},{"path":"pcpipeline.html","id":"debugging-branch-targets","chapter":"9 Poverty Calculator Pipeline (pre-computed estimations)","heading":"Debugging branch targets","text":"challenge debugging branch targets problem specific survey, can’t access “subtarget” using survey ID, something nature, name subtarget created targets using random number. requires little work.Imagine now distributive measures IDN 2015 wrong. see pipeline notice calculations executed target dl_dist_stats, branch target created cache files! look like something like :order find problem IDN 2015, :First, load inputs. Since target dl_mean relatively light object, load directly _targets/ data store. Targets cache_ids aux_pop data frames, lists, also load memory. microdata, however, problematic target cache, one parsed create actual dl_dist_stata target, huge list micro, grouped, imputed data. solution load data frame interest, using either pipload fst.Secondly, need filter list dl_mean data frame cache_ids parse information accepted pipdm::db_compute_dist_stats() function. done debugging actual target done iteratively pattern   =  map(cache, dl_mean, cache_ids).Finally, execute function interest. Notice something else. target aux_pop parsed single data frame pipdm::db_compute_dist_stats() requires way. also one reasons functions pipdm need fixing consistency format inputs.","code":"\ntar_target(name = dl_dist_stats, command = db_compute_dist_stats(dt = cache, mean = dl_mean, pop = aux_pop,\n    cache_id = cache_ids), pattern = map(cache, dl_mean, cache_ids), iteration = \"list\")\n# Load data\ndt <- pipload::pip_load_cache(\"IDN\", 2015, \"PC\")\ntar_load(dl_mean)\ntar_load(cache_ids)\ntar_load(aux_pop)\n\n# Extract corresponding mean and cache ID\nidt <- which(cache_ids == unique(dt$cache_id))\ncache_id <- cache_ids[idt]\nmean_i <- dl_mean[[idt]]\n\n# Esecute the function of interest\ndebugonce(pipdm:::compute_dist_stats)\nds <- pipdm::db_compute_dist_stats(dt = dt, mean = mean_i, pop = aux_pop, cache_id = cache_id)"},{"path":"tmpipelilne.html","id":"tmpipelilne","chapter":"10 Table Maker Pipeline","heading":"10 Table Maker Pipeline","text":"blah blah","code":""},{"path":"load.html","id":"load","chapter":"11 Load microdata and Auxiliary data","heading":"11 Load microdata and Auxiliary data","text":"Make sure packages installed loaded memory. Given hosted Github, code makes sure package PIP workflow can installed correctly.","code":"\n## First specify the packages of interest\npackages = c(\"pipaux\", \"pipload\")\n\n## Now load or install&load all\npackage.check <- lapply(packages, FUN = function(x) {\n    if (!require(x, character.only = TRUE)) {\n        pck_name <- paste0(\"PIP-Technical-Team/\", x)\n        devtools::install_github(pck_name)\n        library(x, character.only = TRUE)\n    }\n})"},{"path":"load.html","id":"auxiilary-data","chapter":"11 Load microdata and Auxiliary data","heading":"11.1 Auxiilary data","text":"Even though pipaux 25 functions, features\ncan executed using pipaux::load_aux pipaux::update_aux functions.","code":""},{"path":"load.html","id":"udpate-data","chapter":"11 Load microdata and Auxiliary data","heading":"11.1.1 udpate data","text":"main function pipaux package udpate_aux. first argument function measure refers measure data loaded. measures available cpi, gdm, gdp, pce, pfw, pop, ppp.","code":"\npipaux::update_aux(measure = \"cpi\")"},{"path":"load.html","id":"load-data","chapter":"11 Load microdata and Auxiliary data","heading":"11.1.2 Load data","text":"Loading auxiliary data job package pipload function pipload::pip_load_aux(), though pipaux also provides pipaux::load_aux() purpose. Notice , though function exactly , loading function pipload prefix pip_ distinguish one pipaux. However, going limit work pipaux update auxiliary data work pipload load data. Thus, examples use pipload loading either microdata auxiliary data.","code":"\ndf <- pipload::pip_load_aux(measure = \"cpi\")\nhead(df)\n#>    country_code cpi_year survey_year    cpi ccf survey_acronym change_cpi2011 cpi2011 cpi_domain\n#> 1:          AGO     2000        2000 0.0339   1            HBS              0  0.0339          1\n#> 2:          AGO     2008        2008 0.7233   1      IBEP-MICS              1  0.7233          1\n#> 3:          AGO     2018        2018 2.9354   1          IDREA              1  2.9354          1\n#> 4:          ALB     1996        1996 0.4445   1            EWS              1  0.4445          1\n#>    cpi_domain_value cpi2011_unadj cpi2011_AM20 cpi2011_unadj_AM20 cpi2005_AM20 cpi_final_2019\n#> 1:                1        0.0339       0.0338             0.0338       0.0719             NA\n#> 2:                1        0.7233       0.7233             0.7233       1.5287             NA\n#> 3:                1        2.9354       3.0606             3.0606           NA             NA\n#> 4:                1        0.4445       0.4444             0.4444       0.5300             NA\n#>    cpi_data_level          cpi_id\n#> 1:       national CPI_v05_M_v01_A\n#> 2:       national CPI_v05_M_v01_A\n#> 3:       national CPI_v05_M_v01_A\n#> 4:       national CPI_v05_M_v01_A\n#>  [ reached getOption(\"max.print\") -- omitted 2 rows ]"},{"path":"load.html","id":"microdata","chapter":"11 Load microdata and Auxiliary data","heading":"11.2 Microdata","text":"Loading PIP microdata practical action pipload package. However, important understand logic microdata.PIP microdata several characteristics,survey Country/Year. happens one welfare variable available income consumption.countries, like Mexico, two different welfare types survey country/year. add layer complexity objective known default one.multiple version harmonized survey. version organized two-type vintage control. possible new version data Raw data–one provided official NSO–updated, un update harmonization process.survey use one analytic tool PIP (e.g., Poverty Calculator, Table Maker, SOL). Thus, data loaded depends tool going used.Thus, order make process finding loading data efficiently, pipload three-step process.","code":""},{"path":"load.html","id":"inventory-file","chapter":"11 Load microdata and Auxiliary data","heading":"11.2.1 Inventory file","text":"inventory file resides y:/PIP-Data/_inventory/inventory.fst. file data frame microdata available PIP structure. two main variables, orig filename. former refers full directory path database, whereas latter file name. variables data frame derived two.inventory file used speed file searching process pipload. previous packages, time user wanted find particular data base, necessary look folder structure extract name file meet particular criteria. time-consuming inefficient. advantage method though, , construction, finds data available. contrast, inventory file method much faster “searching” method, requires load light file data available, filter data, return required information. drawback, however, needs kept date data changes constantly.update inventory file, need use function pip_update_inventory. don’t provide argument, update whole inventory, may take around 10 15 min–function warn . provide country/ies want update, process way faster.","code":"\n# update one country\npip_update_inventory(\"MEX\")\n\n# Load inventory file\ndf <- pip_load_inventory()\nhead(df[, \"filename\"])\n#>                                          filename\n#> 1:       AGO_2000_HBS_V01_M_V01_A_PIP_PC-GPWG.dta\n#> 2: AGO_2008_IBEP-MICS_V02_M_V02_A_PIP_PC-GPWG.dta\n#> 3:  AGO_2008_IBEP-MICS_V02_M_V02_A_PIP_TB-ALL.dta\n#> 4:     AGO_2018_IDREA_V01_M_V01_A_PIP_PC-GPWG.dta\n#> 5:      AGO_2018_IDREA_V01_M_V01_A_PIP_TB-ALL.dta\n#> 6:       ALB_1996_EWS_V01_M_V01_A_PIP_PC-HIST.dta"},{"path":"load.html","id":"finding-data","chapter":"11 Load microdata and Auxiliary data","heading":"11.2.2 Finding data","text":"Every dataset PIP microdata repository identified seven variables! Country code, survey year, survey acronym, master version, alternative version, tool, source. giving user responsibility know different combinations file heavy burden. Thus, data finder, pip_find_data(), provide names files available meet criteria arguments provided user. instance, use wants know file available Paraguay, type,Yet, user need precise request, can add information different arguments function. example, data available 2012,","code":"\npip_find_data(country = \"PRY\")[[\"filename\"]]\n#>  [1] \"PRY_1990_EH_V01_M_V02_A_PIP_PC-GPWG.dta\"  \"PRY_1995_EH_V01_M_V02_A_PIP_PC-GPWG.dta\" \n#>  [3] \"PRY_1997_EIH_V01_M_V03_A_PIP_PC-GPWG.dta\" \"PRY_1999_EPH_V01_M_V03_A_PIP_PC-GPWG.dta\"\n#>  [5] \"PRY_2001_EIH_V01_M_V05_A_PIP_PC-GPWG.dta\" \"PRY_2001_EIH_V01_M_V05_A_PIP_TB-ALL.dta\" \n#>  [7] \"PRY_2002_EPH_V01_M_V05_A_PIP_PC-GPWG.dta\" \"PRY_2002_EPH_V01_M_V05_A_PIP_TB-ALL.dta\" \n#>  [9] \"PRY_2003_EPH_V01_M_V05_A_PIP_PC-GPWG.dta\" \"PRY_2003_EPH_V01_M_V05_A_PIP_TB-ALL.dta\" \n#> [11] \"PRY_2004_EPH_V01_M_V05_A_PIP_PC-GPWG.dta\" \"PRY_2004_EPH_V01_M_V05_A_PIP_TB-ALL.dta\" \n#> [13] \"PRY_2005_EPH_V01_M_V05_A_PIP_PC-GPWG.dta\" \"PRY_2005_EPH_V01_M_V05_A_PIP_TB-ALL.dta\" \n#> [15] \"PRY_2006_EPH_V01_M_V05_A_PIP_PC-GPWG.dta\" \"PRY_2006_EPH_V01_M_V05_A_PIP_TB-ALL.dta\" \n#> [17] \"PRY_2007_EPH_V01_M_V05_A_PIP_PC-GPWG.dta\" \"PRY_2007_EPH_V01_M_V05_A_PIP_TB-ALL.dta\" \n#> [19] \"PRY_2008_EPH_V01_M_V05_A_PIP_PC-GPWG.dta\" \"PRY_2008_EPH_V01_M_V05_A_PIP_TB-ALL.dta\" \n#> [21] \"PRY_2009_EPH_V01_M_V06_A_PIP_PC-GPWG.dta\" \"PRY_2009_EPH_V01_M_V06_A_PIP_TB-ALL.dta\" \n#> [23] \"PRY_2010_EPH_V01_M_V06_A_PIP_PC-GPWG.dta\" \"PRY_2010_EPH_V01_M_V06_A_PIP_TB-ALL.dta\" \n#> [25] \"PRY_2011_EPH_V01_M_V07_A_PIP_PC-GPWG.dta\" \"PRY_2011_EPH_V01_M_V07_A_PIP_TB-ALL.dta\" \n#> [27] \"PRY_2012_EPH_V01_M_V04_A_PIP_PC-GPWG.dta\" \"PRY_2012_EPH_V01_M_V04_A_PIP_TB-ALL.dta\" \n#> [29] \"PRY_2013_EPH_V01_M_V03_A_PIP_PC-GPWG.dta\" \"PRY_2013_EPH_V01_M_V03_A_PIP_TB-ALL.dta\" \n#> [31] \"PRY_2014_EPH_V01_M_V03_A_PIP_PC-GPWG.dta\" \"PRY_2014_EPH_V01_M_V03_A_PIP_TB-ALL.dta\" \n#> [33] \"PRY_2015_EPH_V01_M_V03_A_PIP_PC-GPWG.dta\" \"PRY_2015_EPH_V01_M_V03_A_PIP_TB-ALL.dta\" \n#> [35] \"PRY_2016_EPH_V01_M_V02_A_PIP_PC-GPWG.dta\" \"PRY_2016_EPH_V01_M_V02_A_PIP_TB-ALL.dta\" \n#> [37] \"PRY_2017_EPH_V01_M_V02_A_PIP_PC-GPWG.dta\" \"PRY_2017_EPH_V01_M_V02_A_PIP_TB-ALL.dta\" \n#> [39] \"PRY_2018_EPH_V01_M_V03_A_PIP_PC-GPWG.dta\" \"PRY_2018_EPH_V01_M_V03_A_PIP_TB-ALL.dta\" \n#> [41] \"PRY_2019_EPH_V01_M_V01_A_PIP_PC-GPWG.dta\" \"PRY_2019_EPH_V01_M_V01_A_PIP_TB-ALL.dta\"\npip_find_data(country = \"PRY\", year = 2012)[[\"filename\"]]\n#> [1] \"PRY_2012_EPH_V01_M_V04_A_PIP_PC-GPWG.dta\" \"PRY_2012_EPH_V01_M_V04_A_PIP_TB-ALL.dta\""},{"path":"load.html","id":"loading-data","chapter":"11 Load microdata and Auxiliary data","heading":"11.2.3 Loading data","text":"Function pip_load_data takes care loading data. first instruction within pip_load_data find data avialable repository using pip_load_inventory(). difference however two-fold. First, pip_load_data load default /recent version country/year combination available. Second, gives user possibility load different datasets either list dataframe form. instance, user wants load Paraguay data 2014 2015 used Poverty Calculator tool, may type,","code":"\n\ndf <- pip_load_data(country = \"PRY\", year = c(2014, 2015), tool = \"PC\")\n\njanitor::tabyl(df, survey_id)\n#>                             survey_id     n percent\n#>  PRY_2014_EPH_V01_M_V03_A_PIP_PC-GPWG 20109   0.395\n#>  PRY_2015_EPH_V01_M_V03_A_PIP_PC-GPWG 30737   0.605"},{"path":"docker.html","id":"docker","chapter":"12 Docker Container","heading":"12 Docker Container","text":"Note: Aleksander, please complete section make everything makes sense\nlinks work","code":""},{"path":"docker.html","id":"introduction","chapter":"12 Docker Container","heading":"12.1 Introduction","text":"Docker container PIP Poverty Calculator API application.repository meant develop run Docker container Poverty\nCalculator API local World Bank laptops. DEV, QA Production\ndeployments Azure please refer TFS\nrepository.\ndetails see section Deploying Azure.","code":""},{"path":"docker.html","id":"prerequisites","chapter":"12 Docker Container","heading":"12.2 Prerequisites","text":"Local admin accountDocker Desktop WindowsWSL 2 (recommended)Visual Studio Code (recommended)See Docker World Bank laptops recommendations \ninstall Docker Desktop WSL 2.Visual Code strictly needed, VS Docker\nplugin\none best tools interact Docker.","code":""},{"path":"docker.html","id":"create-volume","chapter":"12 Docker Container","heading":"12.3 Create volume","text":"data used poverty calculations stored outside Docker\ncontainer. therefore need link data source local machine \ncontainer run . accomplished bind\nmount, preferred way \nuse named volume.can create populate volume following steps . First \ncreate empty volume, link temporay container, using\ndocker cp copy files container volume. data \ncopied can discard temporary container.purposes need create volume , remember \nupdate contents volume case data structure changes want\nmake sure container running latest available data. See \nTFS data\nrepo\n(DEV branch) latest data updates.volume can inspected docker inspect docker system\ncommands. running Docker Desktop Windows WSL 2.0 \nphysical location Docker volumes usually found \n\\\\wsl$\\docker-desktop-data\\version-pack-data\\community\\docker\\volumes. \ninformation volumes see Use\nvolumes section Docker’s reference\nmanual.","code":"# Create volume \ndocker volume create pip-vol\n# Mount volume to tmp container  \ndocker run -d --name pip-data --mount type=volume,source=pip-vol,target=/data ubuntu:20.04\n# Copy data to container (and volume)\ndocker cp <data-folder>/. pip-data:data\n# Stop and remove tmp container \ndocker stop pip-data \ndocker rm pip-data"},{"path":"docker.html","id":"build-image","chapter":"12 Docker Container","heading":"12.4 Build image","text":"Docker images built using docker build command. build \nimage set image name pip-api.can also set specific tag image. example can specify \nversion number base image used source. decide tag \nimages . Often tag latest (default) suffice, \ninstances keeping track different versions development image\nuseful.Note layer Dockerfile cached built. layers won’t \nre-run unless code produce specific layer previous layer \nDockerfile changes. handy fast iterations, can also cause \nimage outdated.needed can use ---cache flag force re-build. useful\nwant make sure latest Linux updates installed \nupdating wbpip pipapi R packages. See also Tips \nTricks section partial re-builds.","code":"docker build -t pip-api .# Set tag when building\ndocker build -t pip-api:0.0.4\n# Set tag after build (version number) \ndocker image tag pip-api:latest pip-api:0.0.4\n# Set tag after build (base image)\ndocker image tag pip-api:latest pip-api:ubi8 docker build --no-cache -t pip-api ."},{"path":"docker.html","id":"run-container","chapter":"12 Docker Container","heading":"12.5 Run container","text":"Run container exposing port 80 mounting volume survey \nauxiliary data. data structure attached volume must correspond \nsub-folder specifications R/main.R.Navigate http://localhost/__docs__/ see \nrunning API.details docker run command options see Docker\nDocs.","code":"docker run --rm -d -p 80:80/tcp --mount src=pip-vol,target=/ipp,type=volume,readonly --name pip-api pip-api"},{"path":"docker.html","id":"debugging","chapter":"12 Docker Container","heading":"12.6 Debugging","text":"Run container interactively:Run container interactive mode, using -flag, see output\nmessages.Inspect container:development purposes can useful inspect Docker container.\nLuckily easy enter running container docker exec\ncommand.","code":"$ docker run --rm -it -p 80:80/tcp --mount src=pip-vol,target=/ipp,type=volume,readonly --name pip-api pip-api\nRunning plumber API at http://0.0.0.0:80\nRunning swagger Docs at http://127.0.0.1:80/__docs__/# Enter the container as default user \n$ docker exec -it pip-api /bin/bash\nplumber@bd8ea77299ca:/$ \n# Enter the container as root user\n$ docker exec -it -u 0 pip-api /bin/bash\nroot@bd8ea77299ca:/$ "},{"path":"docker.html","id":"security","chapter":"12 Docker Container","heading":"12.7 Security","text":"Since PIP Techincal Team developing API Docker\ncontainer, also larger responsibility security. deploying \nAzure image need go security scan, provided \nAquasec, generally quite strict. high\nlevel vulnerability found Aquasec scan result failed\ndeployment. possible leverage Aquasec local machines, can\nget indication potential vulnerabilites taking advantage built\nsecurity scan comes Docker. Additionally also possible \nscan contents R packages used image.Note neither Snyk Oyster scans described requirements \nOIS. included additional preliminary tools.Run image security scan:deploying Azure can run preliminary security scans Snyk. See\nVulnerability scanning Docker local\nimages Docker Security Scanning\nGuide 2021 details.important note Aquasec scan runs Azure different\nSnyk scan, can detect different vulnerabilites. Even though \nzero vulnerabilites found Snyk, issues might still detected \nAquasec.Run security scan R packages:can scan R packages inside container {oysteR} package,\nscans R projects insecure dependencies using OSS\nIndex.First log running container root, start R.install {oyster} package, run audit.Note finding zero vulnerabilities guarantee threats. \nexample scanning C++ code inside R packages yet implemented. \ndetails latest developments {oyster} package see \nREADME Github.","code":"docker scan --file .\\Dockerfile pip-api$ docker exec -it -u 0 pip-api /bin/bash\nroot@ab54fbf1eb36:/# R \ninstall.packages(\"oysteR\")\nlibrary(\"oysteR\")\naudit <- audit_installed_r_pkgs()\nget_vulnerabilities(audit)"},{"path":"docker.html","id":"base-image-options","chapter":"12 Docker Container","heading":"12.8 Base image options","text":"development process Dockerfile used different base\nimages.current image main branch based ubi8, options\n(rocker, centos8) available seperate branches. seperate\nbranches actively maintained, kept case \nneed switch another base image future.main need switch base image likely stem Azure DevOps\nsecurity scan. example images based rocker centos8 work well\nlocally, neither pass deployment. CentOS images unfortunately \nlist approved images OIS, \nRocker images (\nbased Ubuntu 20.04 LTS) currently vulnerability\n(CVE-2019-18276) \nclassified high level threat Aqua Scan.fact one Linux dependencies R UBI 8, libX11, also currently\ntrigger high level vulnerability\n(CVE-2020-14363) \nAqua Scan. Even though issue solved offical RHEL 8 release,\nissue still persist UBI 8. can however solved manually\ndownloading newer version libX11 (1.6.12 later), removing \nproblematic version (1.6.8).case need develop base images future \nstrongly recommended start one Linux distributions \nRStudio provides precompiled binaries \nR. avoids need \ninstall R source.","code":""},{"path":"docker.html","id":"deploying-to-azure","chapter":"12 Docker Container","heading":"12.9 Deploying to Azure","text":"Azure repo consists three branches; DEV, QA PROD. PIP Techincal\nTeam access first two, handle deployments \nProduction.Conduct deployments following order:Local:Build image scratch (wo/ caching).Update volume latest available data (sync TFS DEV data\nrepo).Run container interactive mode test API.[Optional] Scan image w/ Snyk potential vulnerabilites.DEV:Copy Dockerfile question local TFS repo, e.g. use\ncopy-dockerfile.ps1 -outdir '../ITSES-POVERTYSCOREAPI.Commit push TFS remote repo.Go Release\npipline\nsee results image build security scan.Vist DEV website\ntesting.QA:checking DEV build working correctly, can commit QA\ncreating PR merge QA branch.Go Release\npipline\nsee results image build security scan.Vist QA website\ntesting.PROD:TBD.","code":""},{"path":"docker.html","id":"tips-and-tricks","chapter":"12 Docker Container","heading":"12.10 Tips and tricks","text":"Start Docker working day opening CMD shell admin-mode run\nsc config LxssManager start=auto. Keep shell open might\nneed re-run command WSL crashes.Turn VPN using Docker. avoids issue WSL crashing\ntime time. still might happen though VPN switces \nautomatically reasons switch back forth.WSL causes much pain, try switching legacy Hyper-V backend.\n(Go Docker Desktop -> General Setting -> Use WSL 2 based engine).Re-build image partial cache adding ARG ENV variable\nright layer want invalidate (yes, hacky \nworks). E.g. something like:","code":"# Install PIP specific R packages \nENV test=test06302021\nRUN Rscript -e \"remotes::install_github('PIP-Technical-Team/wbpip@master', repos = '${CRAN}')\"\nRUN Rscript -e \"remotes::install_github('PIP-Technical-Team/pipapi@master', repos = '${CRAN}')\""},{"path":"docker.html","id":"installation-on-world-bank-laptops","chapter":"12 Docker Container","heading":"12.11 Installation on World Bank laptops","text":"Last updated: 4/19/2021Install Docker\nDekstop (v.\n3.3.0 later)\nRemember check box enable WSL integration.\nInstall Docker\nDekstop (v.\n3.3.0 later)Remember check box enable WSL integration.Activate WSL\nCheck WSL feature Windows activated (e.g. run wsl --help\nPowershell). proceed step 3. Note: get \nmessage saying “service started” try restarting WSL like\nsuggested Known problems \nsolutions.\nGo Control Panel -> Programs -> Turn Windows features \ncheck box Windows Subsystem Linux, follow \nsteps \nprefer activate WSL command line.\nReboot system.\nActivate WSLCheck WSL feature Windows activated (e.g. run wsl --help\nPowershell). proceed step 3. Note: get \nmessage saying “service started” try restarting WSL like\nsuggested Known problems \nsolutions.Go Control Panel -> Programs -> Turn Windows features \ncheck box Windows Subsystem Linux, follow \nsteps \nprefer activate WSL command line.Reboot system.Install WSL 2\nDownload install Linux kernel update\npackage.\nSet WSL 2 default version (run wsl --set-default-version 2\nPowershell).\nInstall WSL 2Download install Linux kernel update\npackage.Set WSL 2 default version (run wsl --set-default-version 2\nPowershell).Configure Docker access privileges\norder run Docker wo/ admin privileges need add \n“docker-users” group.\nOpen Computer Management. Go Local User Groups -> Groups ->\ndocker-users add regular account (WB/wb<UPI>) list \nusers.\nReboot system.\nConfigure Docker access privilegesIn order run Docker wo/ admin privileges need add \n“docker-users” group.Open Computer Management. Go Local User Groups -> Groups ->\ndocker-users add regular account (WB/wb<UPI>) list \nusers.Reboot system.Start Docker Desktop enjoy hard work :-)Start Docker Desktop enjoy hard work :-)","code":""},{"path":"docker.html","id":"known-problems-and-solutions","chapter":"12 Docker Container","heading":"Known problems and solutions","text":"Docker Dekstop sometimes fails following error.root cause problem unclear, many users online report similar\nissues. best solution found far open CMD shell Admin\nmode, run following code restart LxssManager / wsl .also need restart Docker Desktop.possible World Bank VPN connection contributing error.\nTurning VPN completly using Docker might help avoiding\nissue.","code":"System.InvalidOperationException:\nFailed to deploy distro docker-desktop to C:\\Users\\<User>\\AppData\\Local\\Docker\\wsl\\distro: exit code: -1\nstdout: Error: 0xffffffff> sc config LxssManager start=auto\n[SC] ChangeServiceConfig SUCCESS"},{"path":"docker.html","id":"usage","chapter":"12 Docker Container","heading":"12.12 Usage","text":"","code":""},{"path":"docker.html","id":"resources","chapter":"12 Docker Container","heading":"12.13 Resources","text":"See Best practices writing\nDockerfiles\nadvice build Docker images.Follow Docker Windows release\nnotes \ninformation new releases bug fixes.","code":""},{"path":"azure.html","id":"azure","chapter":"13 Deployment in Azure server","heading":"13 Deployment in Azure server","text":"","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
