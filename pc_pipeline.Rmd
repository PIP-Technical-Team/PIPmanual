# Poverty Calculator Pipeline (pre-computed estimations) {#pcpipeline}

The Poverty Calculator Pipeline--hereafter, and only for the rest of this
chapter, pipeline--is the technical procedure to calculate the pre-computed
estimations of the PIP project. These estimations have two main purposes:

1.  Provide the user with instantaneous information about distributive measures
    of all the household surveys in the PIP repository that do not depend on the
    value of the poverty line. Avoiding thus the need for re-computation as it
    was the case in PovcalNet for some of these measures.
2.  Provide the necessary inputs to the PIP API.

This chapter walks you through the folder structure of the folder, the main R
script, `_targets.R`, and the complete and partial execution of the script.
Also, it provides some tips for debugging.

## Folder structure

The pipeline is hosted in the Github repository
[PIP-Technical-Team/pip_ingestion_pipeline](https://github.com/PIP-Technical-Team/pip_ingestion_pipeline).
At the root of the repo you will find a series of files and folders.

```{r, eval=FALSE}
#> +-- batch
#> +-- pip_ingestion_pipeline.Rproj
#> +-- R
#> +-- README.md
#> +-- renv
#> +-- renv.lock
#> +-- run.R
#> +-- _packages.R
#> \-- _targets
#> \-- _targets.R
```

### Folders {.unnumbered}

-   `R` Contains long R functions used during the pipeline

-   `batch` Script for timing the execution of the pipeline. This folder should
    probably be removed

-   `_targets` Folder for all objects created during the pipeline. You don't
    need to look inside as it content is managed by the `targets` package.

-   `renv` Folder for reproducible environment.

### Files {.unnumbered}

-   `_packages.R` Created by `targets::tar_renv()`. Do not modify manually.

-   `_targets.R` Contains the pipeline. This is the most important file.

## Prerequisites

Before you start working on the pipeline, you need to make sure to have the
following PIP packages.

[Note:]{style="color:red"} Notice that directives below have suffixes like
`@development`, which specify the branch of the particular package that you need
to use. Ideally, the master branch of all packages should be used, but that will
only happen until the end of the development process.

[Note2:]{style="color:red"} If you update any of the packages developed by the
PIP team, make sure you always increased the version of the package using the
function `usethis::use_version()`. Even if the change in the package is small,
you need on increased the version of the package. Otherwise, `{targets}` won't
execute the sections of the pipeline that run the functions you changed.

```{r, eval=FALSE}
remotes::install_github("PIP-Technical-Team/pipdm@development")
remotes::install_github("PIP-Technical-Team/pipload@development")
remotes::install_github("PIP-Technical-Team/wbpip@halfmedian_spl")
install.packages("joyn")
```

In case `renv` is not working for you, you may need to install all the packages
mentioned in the `_packages.R` script at the root of the folder. Also, make sure
to install the most recent version of `targets` and `tarchetypes` packages.

## Structure of the `_targets.R` file

Even thought the pipeline script looks like a regular R Script, it is structured
in a specific way in order to make it work with
`{[targets](https://docs.ropensci.org/targets/)}` package, starting by the fact
that it must be called `_targets.R` in the root of the project. It highly
recommended you read the entire [targets
manual](https://books.ropensci.org/targets/) to fully understand how it works.
Also, during this chapter, we will referring to the manual constantly to expand
in any particular targets' concept.

### Start up {.unnumbered}

The first part of the pipeline sets up the environment. It,

1.  loads the `{targets}` and `{tarchetypes}` packages,

```{=html}
<!-- -->
```
2.  creates default values like directories, time stamps, survey and reference
    years boundaries, compression level of .fst files, among other things.
3.  executes `tar_option_set()` to set up some option in `{targets}`. Two
    particular options are important, `packages` and `imports` for tracking
    changes in package dependencies. You can read more about it in sections
    [Loading and configuring R
    packages](https://books.ropensci.org/targets/practices.html#loading-and-configuring-r-packages)
    and [Packages-based
    invalidation](https://books.ropensci.org/targets/practices.html#packages-based-invalidation)
    of the targets manual.
4.  Attach all the packages and functions of the project by running
    `source('_packages.R')` and `source('R/_common.R')`

### Step 1: small functions {.unnumbered}

According to the section [Functions in
pipelines](https://books.ropensci.org/targets/functions.html#functions-in-pipelines)
of the targets manual, it is recommend to only use functions rather than
expressions during the executions. Presumably, the reason for this is that
targets track changes in functions but not in expressions. Thus, this section of
the scripts defines small functions that are executed along the pipeline. In the
section above, the scripts `source('R/_common.R')` loads longer functions. Yet,
keep in mind that the `'R/_common.R'` was used in a previous version of the
pipeline before `{targets}` was implemented. Now, most of the function in
`'R/_common.R'` are included in the `{pipdm}` package.

### Step 2: prepare data {#pipe-prepare-data .unnumbered}

This section used to longer in previous versions of the pipeline because
identified the auxiliary data, loaded he PIP microdata inventory, and created
the cache files. Now, it only identifies the auxiliary data and creates the data
frame `aux_tb`, which is used inside the pipeline to create targets for each
auxiliary file. Not much more to say here.

### Step 3: The actual pipeline

This part of the pipeline is long and it is explained in detail in the next
section. Suffice is to say that the order of the pipeline is the following,

1.  Load all necessary data. That is, auxiliary data and inventories, and then
    create any cache fie that has not been created yet.

2.  Calculate means in LCU

3.  Crate deflated survey mean (DSM) table

4.  Calculate reference year table (aka., interpolated means table)

5.  Calculate distributional stats

6.  Create output tables

    1.  join survey mean table with dist table

    2.  join reference year table with dist table

    3.  coverage table aggregate population at the regional level table

7.  Clean and save.

## Understanding the pipeline

One thing is to understand the how the `{targets}` package works and something
else is to understand how the targets of the Poverty Calculator Pipeline are
created. For the former, you can read the targets manual. For the latter, we
should start by making a distinction between the different types of targets.

In `{targets}` terminology, there are two kinds of targets, **stems** and
**branches**. **Stems** are unitary targets. That is, for each target there is
only one single R object. **Branches**, on the other hand, are targets that
contain several objects or *subtargets* inside (You can learn more about them in
the chapter [Dynamic
branching](https://books.ropensci.org/targets/dynamic.html#dynamic) of the
targets manual). We will see the use of this type of targets when we talk about
the use of cache files.

### Stem targets {.unnumbered}

There are two ways to create **stem** targets: either using `tar_target()` or
using `tar_map()` from the `{tarchetypes}` package. The `tar_map()` function
allows to create **stem** targets iteratively. See for instance the creation of
targets for each auxiliary data,

```{r, eval=FALSE}
tar_map(
  values = aux_tb, 
  names  = "auxname", 
  
  # create dynamic name
  tar_target(
    aux_dir,
    auxfiles, 
    format = "file"
  ), 
  tar_target(
    aux,
    pipload::pip_load_aux(file_to_load = aux_dir,
                          apply_label = FALSE)
  )
  
)
```

`tar_map()` takes the values in the data frame `aux_tb` created in [Step 2:
prepare data] and creates two type of targets. First, it create the target
`aux_dir`, using the file paths in column `auxfiles` of `aux_tb` to let
`{targets}` know that we will have objects that are loaded from a file and are
not created inside the pipeline. This is why we use the option
`format = "file"`. Then, it uses the the column `auxname` of `aux_tb` as the
names of the targets for each auxiliary data frame (prefixed by the word "aux").
This is why we had to add the argument `file_to_load` to
`pipload::pip_load_aux`, so we can let `{targets}` know that the file paths
defined in target `aux_dir` are used to create the targets prefixed with `aux`,
which are the actual targets. For example, if I need to use the population data
frame inside the pipeline, I'd use the target `aux_pop`, which had a
corresponding file path in `aux_dir`. In this way, if the original file
referenced in `aux_dir` changes, all the targets that depend on `aux_pop` will
be run again.

### Branches targets {.unnumbered}

The core of this pipeline

## Executing the `_targets.R` file

awfawef

## Debugging

sdfsdf
